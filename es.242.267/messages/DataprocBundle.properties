action.add.job.title=Enviar trabajo
action.cancel.job.confirm.msg=''{0}'' ¿Quieres cancelar el trabajo?
action.cancel.job.title=Cancelación de trabajo
action.clone.job.title=Replicación de Trabajo
action.cluster.remove.confirm.msg=¿Está seguro de que desea eliminar el clúster ''{0}''?
action.cluster.start.confirm.msg=¿Le gustaría iniciar el clúster ''{0}''?
action.cluster.terminate.confirm.msg=¿Está seguro de que desea finalizar el clúster ''{0}''?
action.confirm.title=controlar
action.delete.job.confirm.msg=¿Está seguro de que desea eliminar el trabajo ''{0}''?
action.delete.job.title=Eliminar trabajo
action.open.stage.bucket=Balde de escenario abierto
action.sftp=Conexión de nodo abierto SFTP
action.sftp.master.node=Abrir conexión de masternode SFTP
action.ssh=Abra SSH para conectarse al nodo
action.ssh.master.node=Conéctese al nodo maestro a través de SSH
add.job.title=Enviar trabajo
add.new.submit.connection.label=Agregar conexión de Dataproc...
cell.execution.finished.msg=Trabajo "{0}" completado con estado {1}
cell.execution.finished.title=Trabajo de procesamiento de datos
cluster.action.delete=Eliminar clúster
cluster.action.start=inicio del cluster
cluster.action.stop=Apagado del clúster
cluster.info.config.autoscaling=Expansión automática\:
cluster.info.config.master.node.desc=Nodo maestro\:
cluster.info.config.metastore=Metaalmacén de Dataproc\:
cluster.info.config.monitoring=Monitoreo de integridad
cluster.info.config.network=red\:
cluster.info.config.region=Región\:
cluster.info.config.scheduled.deletion=Eliminación programada\:
cluster.info.config.secure.boot=Arranque seguro\:
cluster.info.config.vtpm=VTPM\:
cluster.info.config.worker.node.desc=Nodos trabajadores\:
cluster.info.config.zone=área
cluster.info.image.created=Fecha de creación\:
cluster.info.image.version=Versión de la imagen\:
cluster.info.internal.ip=Sólo IP interna\:
cluster.info.optional.components=Componentes opcionales\:
cluster.info.summary.name=nombre\:
cluster.info.summary.state=situación\:
cluster.info.summary.state.details=Detalles de estado\:
cluster.info.summary.type=tipo\:
cluster.info.summary.uiid=UUID del clúster\:
cluster.tab.applications.title=solicitud
cluster.tab.info.title=información
cluster.tab.jobs.title=Trabajo
cluster.tab.name=grupo
cluster.tab.vb.instances.title=instancia de máquina virtual
data.clusterInfo.created=Created
data.clusterInfo.id=ID
data.clusterInfo.name=nombre
data.clusterInfo.region=área
data.clusterInfo.scheduledDeletion=eliminación programada
data.clusterInfo.stagingBucket=cubo de preparación
data.clusterInfo.state=situación
data.clusterInfo.totalWorkers=caminante de armas
data.clusterInfo.zone=región
data.jobInfo.cluster=grupo
data.jobInfo.elapsedTime=tiempo transcurrido
data.jobInfo.id=ID
data.jobInfo.labels=etiqueta
data.jobInfo.startTime=hora de inicio
data.jobInfo.status=situación
data.jobInfo.type=tipo
data.vm.instanceInfo.componentGateway=puerta de enlace de componentes
data.vm.instanceInfo.name=nombre
data.vm.instanceInfo.url=URL
data.web.interfaceInfo.name=nombre
data.web.interfaceInfo.role=role
datamanager.configuration=composición
datamanager.job.info=Informacion del trabajo
datamanager.labels=etiqueta
datamanager.properties=propiedades
datamanager.summary=resumen
dataproc.error=Error de proceso de datos
dataproc.error.cluster.must.be.started=Necesita tener un clúster en ejecución.
dataproc.toolwindow.title=GC Dataproc
default.gcs.connection.name=Proyecto GC Dataproc
emr.remove.linked.connections.title=Conexión de proceso de datos
error.connection.is.not.found=La conexión de Dataproc no está establecida. Por favor crea de nuevo.
error.json.auth.limited.msg=Esta operación solo está disponible cuando se autentica dentro de Dataproc mediante la CLI de gcloud.
error.json.auth.limited.title=Operación no disponible
error.spark.is.not.found=No hay ningún servidor de historial de Spark en el clúster
exportable.DataprocSettings.presentable.name=Herramientas de Big Data Configuración de proceso de datos
exportable.DataprocSshKeyPaths.presentable.name=Herramientas de Big Data Configuración SSH de Dataproc
group.name.dataproc=GC Dataproc
info.value.off=Apagado
instance.config.gpu.number=Número de GPU
instance.config.local.ssd=SSD locales
instance.config.machineType=Tipo de máquina\:
instance.config.primary.disk.size=Tamaño del disco primario\:
instance.config.primary.disk.type=Tipo de disco primario\:
job.hadoop.title=Hadoop
job.hive.title=Hive
job.info.client.tags=etiqueta de cliente
job.info.cluster=grupo\:
job.info.continue.on.failure=Continuar con el fracaso
job.info.elapsed.time=Tiempo transcurrido\:
job.info.jobId=Identificación del trabajo\:
job.info.jobUuid=UUID de trabajo\:
job.info.max.restart.per.hour=Reinicios máximos por hora\:
job.info.max.restart.per.hour.hint=Déjelo en blanco si no desea que el trabajo se reinicie automáticamente cuando falle.
job.info.open.job.files=Mostrar carpeta de trabajo dentro de GCS
job.info.properties=propiedades
job.info.query.file=Consultas\:
job.info.query.file.value=Archivo de consulta\:
job.info.query.text.value=Texto de consulta\:
job.info.query.type=Fuente de consulta\:
job.info.single.file.hint=Puede ser un archivo GCS con el prefijo gs\://, un archivo HDFS con el prefijo hdfs\:// en el clúster o un archivo local con el prefijo file\:// en el clúster.
job.info.spark.additional.py.files=Archivos adicionales de Python\:
job.info.spark.additional.py.files.title=Seleccionar archivos Py adicionales
job.info.spark.additional.r.files=Archivos R adicionales\:
job.info.spark.additional.r.files.title=Seleccionar archivos R adicionales
job.info.spark.archives=Archivo\:
job.info.spark.archives.hint=Los archivos comprimidos se extraen del directorio de trabajo de Spark. Puede ser un archivo GCS con el prefijo gs\://, un archivo HDFS con el prefijo hdfs\:// en el clúster o un archivo local con el prefijo file\:// en el clúster. Tipos de archivos admitidos\: .jar, .tar, .tar.gz, .tgz, .zip.
job.info.spark.archives.title=Seleccionar archivo
job.info.spark.args=tomar el control\:
job.info.spark.files=archivo\:
job.info.spark.jars=Jar\:
job.info.spark.jars.hint=Los archivos jar se incluyen en CLASSPATH. Puede ser un archivo GCS con el prefijo gs\://, un archivo HDFS con el prefijo hdfs\:// en el clúster o un archivo local con el prefijo file\:// en el clúster.
job.info.spark.jars.title=JAR
job.info.spark.main.class=clase principal\:
job.info.spark.main.py.file.title=Seleccione el archivo Py principal
job.info.spark.main.pyfile=Archivo principal de Python\:
job.info.spark.main.r.file=Archivo R principal\:
job.info.spark.main.r.file.title=Seleccione el archivo R principal
job.info.start.date=fecha de inicio\:
job.info.status=situación\:
job.info.status.details=Detalles de estado\:
job.info.type=El tipo de trabajo\:
job.label.block.title=etiqueta
job.pig.title=Pig
job.presto.title=Presto
job.properties.block.title=propiedades
job.pyspark.title=PySpark
job.query.file.dialog.title=Seleccionar archivo de consulta\:
job.query.file.label=Archivo de consulta\:
job.query.source.file=archivo
job.query.source.text=texto
job.query.source.type=Tipo de consulta\:
job.query.text.hint=consulta para ejecutar
job.query.text.label=Texto de consulta\:
job.spark.r.title=SparkR
job.spark.sql.title=SparkSql
job.spark.title=Spark
job.state.active=activación
job.state.canceled=Cancelado
job.state.done=completo
job.state.failed=falla
job.validation.file.archive={0} debe ser un tipo de archivo como .jar, .tar, .tar.gz, .tgz, .zip
job.validation.file.fs={0} debe ser un archivo con el prefijo gs\://, hdfs\:// o file\://
metainfo.cluster.id=ID\:
metainfo.cluster.name=nombre\:
metainfo.cluster.status=situación\:
remote.target.emr.cluster.remark=Dataproc
resolve.artifact.is.not.supported=No se admite la detección de clase principal de {0}.
settings.application.class.name.error.msg=Seleccione primero el archivo jar
task.init.ssh.perform.cli.command=Ejecutando el comando CLI de GCloud...
task.init.ssh.title=Ejecución de la CLI de Dataproc
