action.BigDataTools.Deploy.Configure.text=Spark Submit 구성 생성...
action.open.local.run.config=로컬 Spark Submit
action.open.ssh.run.config=SSH Spark Submit
add.new.ssh.connection.label=SSH 연결 추가...
artifact.tooltip=클러스터에서 실행할 실행 파일의 경로
cluster.manager.kubernetes=Kubernetes
cluster.manager.local=로컬
cluster.manager.mesos=Apache Mesos
cluster.manager.nomad=Nomad
cluster.manager.standalone=독립실행형
cluster.manager.tooltip=서버에서 구성된 클러스터 관리자.
cluster.manager.yarn=Hadoop YARN
cluster.status.loading=로드 중...
cluster.status.no.target=타깃 없음
configuration.description=Spark Submit 구성
configuration.name=Spark Submit
configuration.name.cluster=클러스터
configuration.name.local=로컬(더는 사용되지 않음)
configuration.name.ssh=SSH (지원 중단됨)
configuration.options.add=추가 사용자화
configuration.options.add.title=제출 옵션 추가
dialog.archives.title=아카이브 파일 선택
dialog.artifactPath.title=애플리케이션 선택
dialog.driverClassPath.title=드라이버 클래스 경로 선택
dialog.driverLibraryPath.title=드라이버 라이브러리 경로 선택
dialog.files.title=파일 선택
dialog.input.spark.command.description=Spark Submit 양식을 입력하려면 여기에 spark-submit 명령어를 붙여넣으세요
dialog.input.spark.command.label=Spark 명령어
dialog.input.spark.command.title=Spark 입력
dialog.jars.title=Jar 파일 선택
dialog.keytabFile.title=Keytab 파일 선택
dialog.message.failed.to.create.ssh.process=SSH 프로세스를 생성하지 못했습니다
dialog.message.not.found={0}을(를) 찾을 수 없습니다
dialog.message.spark.home.should.be.set.to.correct.folder=$SPARK_HOME을 올바른 폴더로 설정해야 합니다
dialog.message.specify.application=애플리케이션을 지정하세요
dialog.propertiesFile.title=프로퍼티 파일 선택
dialog.pyfiles.title=Python 파일 선택
dialog.select.artifact.button.open.artifact.settings=아티팩트 설정
dialog.select.artifact.empty=현재 프로젝트에 아티팩트가 없습니다
dialog.select.artifact.link.open.artifact.settings=아티팩트 설정
dialog.select.artifact.title=종속성 아티팩트 선택
dialog.select.class.empty=선택된 애플리케이션에서 클래스를 찾을 수 없습니다
dialog.select.class.title=클래스 이름
dialog.sparkHomePath.title=Spark 홈 디렉터리 선택
dialog.targetDirectory.title=타깃 디렉터리 선택
dialog.workDir.title=작업 디렉터리 선택
edit.ssh.configuration=SSH 구성 편집
error.ssh=Specify SSH Config
error.ssh.config=SSH 구성이 지정되어야 합니다
error.target.config=원격 대상 선택
error.target.id=Select Remote ID
fun.search.process.text={0} 처리
load.command.string=spark-submit 명령어 로드
notification.group.sftpsparkfileupload=Spark용 SFTP 파일 업로드
open.cluster.info.description=문서를 열려면 클릭하세요
progress.text.upload.to.host=호스트로 {0} 업로드...
receive.artifact.task=아티팩트 수신...
remote.target.ssh.remark=SSH 구성
row.final.command=결과 제출 명령어
row.final.command.copy=spark-submit 명령어 복사
row.final.command.hint=spark-submit 명령어를 복사하거나 로드하면 해당하는 필드가 입력됩니다
settings.additional.title=고급 제출 옵션
settings.additional.verbose=추가 디버그 출력 표시
settings.application=애플리케이션:
settings.application.arguments=실행 인수:
settings.application.class.hint=--class 애플리케이션의 메인 클래스(Java/Scala 앱용).
settings.application.class.name=클래스:
settings.application.class.name.error.msg=애플리케이션을 먼저 지정하세요
settings.application.hint=메인 클래스의 메인 메서드에 전달되는 인수(해당하는 경우).
settings.beforeShellScript=제출 스크립트 전
settings.beforeShellScript.hint=Spark Submit 전에 실행될 스크립트입니다. 예: 'source activate py36'
settings.cluster.manager=클러스터 관리자:
settings.cluster.manager.proxy.user=프록시 사용자:
settings.cluster.manager.proxy.user.hint=<html>--proxy-user 애플리케이션을 제출할 때 가장할 사용자.<br>해당 인수는 --principal/--keytab과 사용 시 효과가 없습니다.</html>
settings.cluster.manager.queue=큐:
settings.cluster.manager.queue.hint=--queue 제출할 YARN 큐(디폴트 값: 'default').
settings.cluster.manager.supervise=감독 활성화
settings.cluster.manager.supervise.hint=--supervise 지정하면 드라이버 실패 시 재시작됩니다.
settings.dependencies.files=파일:
settings.dependencies.files.hint=--files 각 실행기의 작업 디렉터리에 배치될 파일의 쉼표로 구분된 목록입니다. 실행기 내 파일의 경로는 SparkFiles.get(fileName)으로 액세스할 수 있습니다.
settings.dependencies.jars=Jar:
settings.dependencies.jars.hint=--jars 드라이버 및 실행기 클래스 경로에 포함되는 jar의 쉼표로 구분된 목록입니다.
settings.dependencies.python=Py 파일:
settings.dependencies.python.hint=--py-files Python 앱의 PYTHONPATH에 추가할 .zip, .egg 또는 .py 파일의 쉼표로 구분된 목록입니다.
settings.dependencies.title=종속성
settings.deploy.mode=배포 모드:
settings.deploy.mode.hint=<html>--deploy-mode 드라이버 프로그램을 로컬('클라이언트')에서 실행할지,<br>클러스터 내('클러스터')에 있는 워커 머신 중 하나에서 실행할지 여부.</html>
settings.deploymode.client=클라이언트
settings.deploymode.cluster=클러스터
settings.driver.class.path=드라이버 클래스 경로:
settings.driver.class.path.hint=<html>--driver-class-path 드라이버에 전달할 추가 클래스 경로<br>--jars로 추가된 jar는 자동으로 클래스 경로에 포함됩니다.</html>
settings.driver.cores=드라이버 코어:
settings.driver.cores.hint=--driver-cores 드라이버가 사용하는 코어 수(클러스터 모드에서만).
settings.driver.java.options=드라이버 Java 옵션:
settings.driver.java.options.hint=--driver-java-options 드라이버에 전달할 추가 Java 옵션.
settings.driver.library.path=드라이버 라이브러리 경로:
settings.driver.library.path.hint=--driver-library-path 드라이버에 전달할 추가 라이브러리 경로.
settings.driver.memory=드라이버 메모리:
settings.driver.memory.hint=--driver-memory 드라이버 메모리(예: 1000M, 2G).
settings.driver.title=드라이버
settings.envParams=환경 변수
settings.envParams.hint=추가 환경 변수
settings.executor.archives=아카이브:
settings.executor.archives.hint=<html>--archives 각 실행기의 작업 디렉터리로 추출될 아카이브의 목록.</html>
settings.executor.cores=실행기 코어:
settings.executor.cores.hint=<html>--executor-cores 실행기당 코어 수<br>(디폴트 값: YARN 모드에서 1 또는 독립실행형 모드에서 워커에 있는 모든 가용 코어 수).</html>
settings.executor.cores.total=총 실행기 코어:
settings.executor.cores.total.hint=--total-executor-cores 모든 실행기의 총 코어 수.
settings.executor.memory=실행기 메모리:
settings.executor.memory.default=1G
settings.executor.memory.hint=--executor-memory 실행기당 메모리(예: 1000M, 2G)
settings.executor.number=실행기 수:
settings.executor.number.hint=<html>--num-executors 실행할 실행기의 수<br>동적 할당이 활성화된 경우, 최초 실행기의 수는 최솟값입니다.</html>
settings.executor.title=실행기
settings.integration.spark.monitoring=연결:
settings.integration.spark.monitoring.add=새로 추가
settings.integration.title=Spark 모니터링 통합
settings.isInteractive=대화형
settings.isInteractive.hint=셸 대화형 모드에서 실행 명령어 실행
settings.kerberos.keytab=Keytab:
settings.kerberos.keytab.hint=<html>--keytab 위에서 지정된 규칙의 keytab을 포함하는 파일의 전체 경로<br>이 keytab은 Secure Distributed Cache를 통해 Application Master를 실행 중인 노드로 복사되어<br>정기적으로 로그인 티켓과 위임 토큰을 갱신합니다.</html>
settings.kerberos.principal=규칙:
settings.kerberos.principal.hint=--principal 안전한 HDFS에서 실행되는 동안 KDC에 로그인할 때 사용할 규칙.
settings.kerberos.title=Kerberos
settings.master=마스터:
settings.master.hint=--master spark://host:port, mesos://host:port, yarn, k8s: //https://host:port 또는 로컬(디폴트 값: local[*]).
settings.maven.exclude.packages=패키지 제외:
settings.maven.exclude.packages.hint=<html>--exclude-packages 종속성 충돌을 피하기 위해<br>--packages에 제공된 종속성을 해결할 때 제외할 groupId:artifactId의 목록.</html>
settings.maven.packages=패키지:
settings.maven.packages.hint=<html>--packages 드라이버와 실행기 클래스 경로에 포함할 Maven 좌표의 목록<br>로컬 Maven 저장소를 검색한 다음, Maven 중앙 저장소 및 --repositories로 지정된 원격 저장소를 검색합니다<br>좌표 서식은 groupId:artifactId:version이어야 합니다.</html>
settings.maven.repositories=저장소:
settings.maven.repositories.hint=--repositories --packages로 주어진 Maven 좌표를 검색할 추가적인 원격 저장소의 목록.
settings.maven.title=Maven
settings.run.target.config=원격 타깃:
settings.shell.title=셸 옵션
settings.shellExecutor=셸 경로
settings.shellExecutor.hint=셸 경로. 대화형 모드가 활성화되어 있거나 제출 스크립트가 설정되기 전에 사용됩니다
settings.spark.config=구성:
settings.spark.config.hint=--conf Spark 구성 프로퍼티입니다.
settings.spark.home=Spark 홈:
settings.spark.properties.file=프로퍼티 파일:
settings.spark.properties.file.hint=<html>--properties-file 추가 프로퍼티를 로드해 올 파일의 경로.<br>지정하지 않을 경우 conf/spark-defaults.conf를 찾습니다.</html>
settings.spark.python.sdk=Python 환경으로 실행:
settings.spark.title=Spark 구성
settings.ssh.config=SSH 구성:
settings.ssh.error.msg=SSH 구성을 먼저 선택하세요
settings.ssh.error.title=파일 선택기 오류
settings.ssh.target.dir=타깃 업로드 디렉터리:
settings.ssh.target.dir.hint=<html>모든 로컬 파일이 업로드될 원격 호스트상의 디렉터리 경로를 입력하세요.<br>선택된 파일이 이 디렉터리에 이미 있는 경우 덮어쓰기 됩니다.</html>
settings.ssh.title=SFTP 옵션
settings.url.artifact.name=IDEA 아티팩트
settings.url.custom.name=사용자 지정
settings.url.file.name=파일
settings.url.gcs.name=GC 스토리지
settings.url.gradle.artifact.name=Gradle 아티팩트
settings.url.gradle.artifact.tooltip=Gradle 아티팩트
settings.url.hdfs.name=HDFS
settings.url.s3.name=S3
settings.url.server.mock.desc=파일 경로:
settings.url.server.name=서버 파일
settings.url.upload.name=파일 업로드
settings.url.upload.tooltip=로컬 파일 업로드
settings.url.web.name=원격
settings.workingDirectory=작업 디렉터리
setup.ssh.config=SSH 구성 설정
spark.submit.gutter.icon.tooltip=Spark 클러스터에서 실행
sparkhome.tooltip=Spark 디렉터리
upload.file.title=원격으로 파일 업로드
upload.files.error=파일 업로드 중 예외가 발생했습니다. {0}
upload.files.success={0}개 파일을 성공적으로 업로드했습니다
upload.files.through.sftp.to.spark.host=SFTP를 통해 파일 업로드
upload.target.dir.is.not.found=타깃 디렉터리 ''{0}''을(를) 찾을 수 없습니다
work.directory.tooltip=스크립트 호출 위치를 가리킵니다