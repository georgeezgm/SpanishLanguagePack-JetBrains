action.add.job.title=Submit Job
action.cancel.job.confirm.msg=''{0}'' ¿Quieres cancelar el trabajo?
action.cancel.job.title=Cancelación de trabajo
action.clone.job.title=Replicación de Trabajo
action.cluster.remove.confirm.msg=¿Está seguro de que desea eliminar el clúster ''{0}''?
action.cluster.start.confirm.msg=¿Le gustaría iniciar el clúster ''{0}''?
action.cluster.terminate.confirm.msg=¿Está seguro de que desea finalizar el clúster ''{0}''?
action.confirm.title=Controlar
action.delete.job.confirm.msg=¿Está seguro de que desea eliminar el trabajo ''{0}''?
action.delete.job.title=Eliminar trabajo
action.open.stage.bucket=Balde de escenario abierto
action.sftp=Conexión de nodo abierto SFTP
action.sftp.master.node=Abrir conexión de masternode SFTP
action.ssh=Abra SSH para conectarse al nodo
action.ssh.master.node=Conéctese al nodo maestro a través de SSH
add.job.title=Submit Job
add.new.submit.connection.label=Agregar conexión de Dataproc...
cell.execution.finished.msg=Trabajo "{0}" completado con estado {1}
cell.execution.finished.title=Trabajo de procesamiento de datos
cluster.action.delete=Eliminar clúster
cluster.action.start=Inicio del cluster
cluster.action.stop=Terminate Cluster...
cluster.info.config.autoscaling=Autoscaling:
cluster.info.config.master.node.desc=Master node:
cluster.info.config.metastore=Dataproc Metastore:
cluster.info.config.monitoring=Integrity Monitoring:
cluster.info.config.network=Red:
cluster.info.config.region=Área:
cluster.info.config.scheduled.deletion=Scheduled deletion:
cluster.info.config.secure.boot=Secure boot:
cluster.info.config.vtpm=VTPM:
cluster.info.config.worker.node.desc=Worker nodes:
cluster.info.config.zone=Zone
cluster.info.image.created=Created:
cluster.info.image.version=Image version:
cluster.info.internal.ip=Internal IP only:
cluster.info.optional.components=Optional components:
cluster.info.summary.name=Nombre:
cluster.info.summary.state=Situación:
cluster.info.summary.state.details=State details:
cluster.info.summary.type=Tipo:
cluster.info.summary.uiid=Cluster UUID:
cluster.tab.applications.title=Solicitud
cluster.tab.info.title=Información
cluster.tab.jobs.title=Trabajo
cluster.tab.name=Grupo
cluster.tab.vb.instances.title=VM Instances
data.clusterInfo.created=Created
data.clusterInfo.id=ID
data.clusterInfo.name=nombre
data.clusterInfo.region=área
data.clusterInfo.scheduledDeletion=eliminación programada
data.clusterInfo.stagingBucket=cubo de preparación
data.clusterInfo.state=situación
data.clusterInfo.totalWorkers=caminante de armas
data.clusterInfo.zone=región
data.jobInfo.cluster=grupo
data.jobInfo.elapsedTime=tiempo transcurrido
data.jobInfo.id=ID
data.jobInfo.labels=etiqueta
data.jobInfo.startTime=hora de inicio
data.jobInfo.status=situación
data.jobInfo.type=tipo
data.vm.instanceInfo.componentGateway=puerta de enlace de componentes
data.vm.instanceInfo.name=nombre
data.vm.instanceInfo.url=URL
data.web.interfaceInfo.name=nombre
data.web.interfaceInfo.role=role
datamanager.configuration=Composición
datamanager.job.info=Informacion del trabajo
datamanager.labels=Etiqueta
datamanager.properties=Propiedades
datamanager.summary=Resumen
dataproc.error=Error de proceso de datos
dataproc.error.cluster.must.be.started=Necesita tener un clúster en ejecución.
dataproc.toolwindow.title=GC Dataproc
default.gcs.connection.name=GC Dataproc project
emr.remove.linked.connections.title=Dataproc connections
error.connection.is.not.found=No se establece la conexión con Dataproc. Por favor crea de nuevo.
error.json.auth.limited.msg=Esta operación solo está disponible cuando se autentica dentro de Dataproc mediante la CLI de gcloud.
error.json.auth.limited.title=Operación no disponible
error.spark.is.not.found=No hay ningún servidor de historial de Spark en el clúster
exportable.DataprocSettings.presentable.name=Herramientas de Big Data Configuración de proceso de datos
exportable.DataprocSshKeyPaths.presentable.name=Herramientas de Big Data Configuración SSH de Dataproc
group.name.dataproc=GC Dataproc
info.value.off=Apagado
instance.config.gpu.number=Number of GPUs
instance.config.local.ssd=Local SSDs
instance.config.machineType=Machine type:
instance.config.primary.disk.size=Primary disk size:
instance.config.primary.disk.type=Primary disk type:
job.hadoop.title=Hadoop
job.hive.title=Hive
job.info.client.tags=Client tags
job.info.cluster=Grupo:
job.info.continue.on.failure=Continue on failure
job.info.elapsed.time=Elapsed time:
job.info.jobId=Job ID:
job.info.jobUuid=Job UUID:
job.info.max.restart.per.hour=Max restart per hour
job.info.max.restart.per.hour.hint=Leave blank if you don't want to allow automatic restarts on job failure.
job.info.open.job.files=Mostrar carpeta de trabajo dentro de GCS
job.info.properties=Propiedades
job.info.query.file=Consultas:
job.info.query.file.value=Query file:
job.info.query.text.value=Query text:
job.info.query.type=Query source:
job.info.single.file.hint=Can be a GCS file with the gs:// prefix, an HDFS file on the cluster with the hdfs:// prefix, or a local file on the cluster with the file:// prefix
job.info.spark.additional.py.files=Additional python files:
job.info.spark.additional.py.files.title=Select Additional Py File
job.info.spark.additional.r.files=Addtional R files:
job.info.spark.additional.r.files.title=Select Additional R File
job.info.spark.archives=Archives:
job.info.spark.archives.hint=Archive files are extracted in the Spark working directory. Can be a GCS file with the gs:// prefix, an HDFS file on the cluster with the hdfs:// prefix, or a local file on the cluster with the file:// prefix. Supported file types: .jar, .tar, .tar.gz, .tgz, .zip.
job.info.spark.archives.title=Select Archive
job.info.spark.args=Tomar el control:
job.info.spark.files=Archivo:
job.info.spark.jars=Jars:
job.info.spark.jars.hint=Jar files are included in the CLASSPATH. Can be a GCS file with the gs:// prefix, an HDFS file on the cluster with the hdfs:// prefix, or a local file on the cluster with the file:// prefix.
job.info.spark.jars.title=JARs
job.info.spark.main.class=Clase principal:
job.info.spark.main.py.file.title=Select Main Py File
job.info.spark.main.pyfile=Main python file:
job.info.spark.main.r.file=Main R file:
job.info.spark.main.r.file.title=Select Main R File
job.info.start.date=Start Date:
job.info.status=Situación:
job.info.status.details=Status details:
job.info.type=Job type:
job.label.block.title=Etiqueta
job.pig.title=Pig
job.presto.title=Presto
job.properties.block.title=Propiedades
job.pyspark.title=PySpark
job.query.file.dialog.title=Select Query File:
job.query.file.label=Query file:
job.query.source.file=Archivo
job.query.source.text=Texto
job.query.source.type=Query type:
job.query.text.hint=The query to execute
job.query.text.label=Query text:
job.spark.r.title=SparkR
job.spark.sql.title=SparkSql
job.spark.title=Spark
job.state.active=Activación
job.state.canceled=Cancelado
job.state.done=Completo
job.state.failed=Falla
job.validation.file.archive={0} must be archive type .jar, .tar, .tar.gz, .tgz, .zip.
job.validation.file.fs={0} must be file with the gs://, hdfs:// or file:// prefix
metainfo.cluster.id=ID:
metainfo.cluster.name=Nombre:
metainfo.cluster.status=Situación:
remote.target.emr.cluster.remark=Clúster de proceso de datos
resolve.artifact.is.not.supported=No se admite la detección de clase principal de {0}.
settings.application.class.name.error.msg=Seleccione primero el archivo jar
task.init.ssh.perform.cli.command=Ejecutando el comando CLI de GCloud...
task.init.ssh.title=Ejecución de la CLI de Dataproc
